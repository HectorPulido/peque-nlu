{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peque_nlu.intent_engines import SGDIntentEngine\n",
    "from peque_nlu.intent_classifiers import ModelIntentClassifier\n",
    "from peque_nlu.feature_extractors import GloveFeatureExtractor\n",
    "from peque_nlu.savers import PickleSaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hectorpulido/own-projects/peque-nlu/.venv/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/hectorpulido/own-projects/peque-nlu/.venv/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['algun', 'com', 'contr', 'cuand', 'desd', 'dond', 'durant', 'eram', 'estab', 'estais', 'estam', 'estan', 'estand', 'estaran', 'estaras', 'esteis', 'estem', 'esten', 'estes', 'estuv', 'fuer', 'fues', 'fuim', 'fuist', 'hab', 'habr', 'habran', 'habras', 'hast', 'hem', 'hub', 'mas', 'mia', 'mias', 'mio', 'mios', 'much', 'nad', 'nosotr', 'nuestr', 'par', 'per', 'poc', 'porqu', 'qui', 'seais', 'seam', 'sent', 'ser', 'seran', 'seras', 'si', 'sient', 'sint', 'sobr', 'som', 'suy', 'tambien', 'tant', 'ten', 'tendr', 'tendran', 'tendras', 'teng', 'tien', 'tod', 'tuv', 'tuy', 'vosotr', 'vuestr'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "sgd_intent_engine = SGDIntentEngine(\"spanish\")\n",
    "model = ModelIntentClassifier(\"spanish\", sgd_intent_engine)\n",
    "model.fit(\"intents_example.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intends': [{'text': 'Hola como te encuentras?',\n",
       "   'intent': 'small_talk',\n",
       "   'probability': 0.9584517167976547},\n",
       "  {'text': 'Quiero aprender sobre lo último de python',\n",
       "   'intent': 'search',\n",
       "   'probability': 0.7631479090976756},\n",
       "  {'text': 'describeme usando un meme',\n",
       "   'intent': 'meme',\n",
       "   'probability': 0.8411252557902885}]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.multiple_predict(\n",
    "    [\n",
    "        \"Hola como te encuentras?\",\n",
    "        \"Quiero aprender sobre lo último de python\",\n",
    "        \"describeme usando un meme\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as gd\n",
    "\n",
    "glove_vectors = gd.load(\"glove-twitter-25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle_saver = PickleSaver()\n",
    "# model = LogisticIntentClassifier.load(pickle_saver, \"model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hectorpulido/own-projects/peque-nlu/.venv/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/hectorpulido/own-projects/peque-nlu/.venv/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['algun', 'com', 'contr', 'cuand', 'desd', 'dond', 'durant', 'eram', 'estab', 'estais', 'estam', 'estan', 'estand', 'estaran', 'estaras', 'esteis', 'estem', 'esten', 'estes', 'estuv', 'fuer', 'fues', 'fuim', 'fuist', 'hab', 'habr', 'habran', 'habras', 'hast', 'hem', 'hub', 'mas', 'mia', 'mias', 'mio', 'mios', 'much', 'nad', 'nosotr', 'nuestr', 'par', 'per', 'poc', 'porqu', 'qui', 'seais', 'seam', 'sent', 'ser', 'seran', 'seras', 'si', 'sient', 'sint', 'sobr', 'som', 'suy', 'tambien', 'tant', 'ten', 'tendr', 'tendran', 'tendras', 'teng', 'tien', 'tod', 'tuv', 'tuy', 'vosotr', 'vuestr'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = ModelIntentClassifier(\"spanish\")\n",
    "model.fit(\"intents_example.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intends': [{'text': 'Hola como te encuentras?',\n",
       "   'intent': 'small_talk',\n",
       "   'probability': 0.5897216782009043},\n",
       "  {'text': 'Hola puedes ayudarme con un problema de matematicas?',\n",
       "   'intent': 'doubts',\n",
       "   'probability': 0.37216194701918215},\n",
       "  {'text': 'describeme usando un meme',\n",
       "   'intent': 'meme',\n",
       "   'probability': 0.5916068948231568}]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.multiple_predict(\n",
    "    [\n",
    "        \"Hola como te encuentras?\",\n",
    "        \"Hola puedes ayudarme con un problema de matematicas?\",\n",
    "        \"describeme usando un meme\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = GloveFeatureExtractor(glove_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hectorpulido/own-projects/peque-nlu/.venv/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/hectorpulido/own-projects/peque-nlu/.venv/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['algun', 'com', 'contr', 'cuand', 'desd', 'dond', 'durant', 'eram', 'estab', 'estais', 'estam', 'estan', 'estand', 'estaran', 'estaras', 'esteis', 'estem', 'esten', 'estes', 'estuv', 'fuer', 'fues', 'fuim', 'fuist', 'hab', 'habr', 'habran', 'habras', 'hast', 'hem', 'hub', 'mas', 'mia', 'mias', 'mio', 'mios', 'much', 'nad', 'nosotr', 'nuestr', 'par', 'per', 'poc', 'porqu', 'qui', 'seais', 'seam', 'sent', 'ser', 'seran', 'seras', 'si', 'sient', 'sint', 'sobr', 'som', 'suy', 'tambien', 'tant', 'ten', 'tendr', 'tendran', 'tendras', 'teng', 'tien', 'tod', 'tuv', 'tuy', 'vosotr', 'vuestr'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = ModelIntentClassifier(\"spanish\", feature_extractor=extractor)\n",
    "model.fit(\"intents_example.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intends': [{'text': 'Hola como te encuentras?',\n",
       "   'intent': 'small_talk',\n",
       "   'probability': 0.5897216782009043,\n",
       "   'features': [{'word': 'hola',\n",
       "     'entity': 'timing',\n",
       "     'similarities': 0.45765376},\n",
       "    {'word': 'encuentras', 'entity': 'timing', 'similarities': 0.3500132}]},\n",
       "  {'text': 'Hola puedes ayudarme con un problema con python?',\n",
       "   'intent': 'doubts',\n",
       "   'probability': 0.36227190356855377,\n",
       "   'features': [{'word': 'hola',\n",
       "     'entity': 'timing',\n",
       "     'similarities': 0.45765376},\n",
       "    {'word': 'puedes', 'entity': 'timing', 'similarities': 0.48465785},\n",
       "    {'word': 'ayudarme', 'entity': 'timing', 'similarities': 0.32324135},\n",
       "    {'word': 'problema', 'entity': 'timing', 'similarities': 0.32983372},\n",
       "    {'word': 'python', 'entity': 'technology', 'similarities': 1},\n",
       "    {'word': 'python', 'entity': 'timing', 'similarities': 0.2627859}]},\n",
       "  {'text': 'describeme usando un meme',\n",
       "   'intent': 'meme',\n",
       "   'probability': 0.5916068948231568,\n",
       "   'features': [{'word': 'usando',\n",
       "     'entity': 'timing',\n",
       "     'similarities': 0.30181673},\n",
       "    {'word': 'meme', 'entity': 'timing', 'similarities': 0.18207678}]}]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.multiple_predict(\n",
    "    [\n",
    "        \"Hola como te encuentras?\",\n",
    "        \"Hola puedes ayudarme con un problema con python?\",\n",
    "        \"describeme usando un meme\",\n",
    "    ],\n",
    "    threshold=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peque_nlu.intent_engines import WorldVectorIntentEngine\n",
    "\n",
    "engine = WorldVectorIntentEngine(\"spanish\", glove_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelIntentClassifier(\n",
    "    \"spanish\", intent_engine=engine, feature_extractor=extractor\n",
    ")\n",
    "model.fit(\"intents_example.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intends': [{'text': 'Hola como te encuentras?',\n",
       "   'intent': 'small_talk',\n",
       "   'probability': 0.4862217023589639,\n",
       "   'features': [{'word': 'hola',\n",
       "     'entity': 'timing',\n",
       "     'similarities': 0.45765376},\n",
       "    {'word': 'encuentras', 'entity': 'timing', 'similarities': 0.3500132}]},\n",
       "  {'text': 'Hola puedes ayudarme con un problema con python?',\n",
       "   'intent': 'thanks',\n",
       "   'probability': 0.5628193948223007,\n",
       "   'features': [{'word': 'hola',\n",
       "     'entity': 'timing',\n",
       "     'similarities': 0.45765376},\n",
       "    {'word': 'puedes', 'entity': 'timing', 'similarities': 0.48465785},\n",
       "    {'word': 'ayudarme', 'entity': 'timing', 'similarities': 0.32324135},\n",
       "    {'word': 'problema', 'entity': 'timing', 'similarities': 0.32983372},\n",
       "    {'word': 'python', 'entity': 'technology', 'similarities': 1},\n",
       "    {'word': 'python', 'entity': 'timing', 'similarities': 0.2627859}]},\n",
       "  {'text': 'describeme usando un meme',\n",
       "   'intent': 'meme',\n",
       "   'probability': 0.3286874629335567,\n",
       "   'features': [{'word': 'usando',\n",
       "     'entity': 'timing',\n",
       "     'similarities': 0.30181673},\n",
       "    {'word': 'meme', 'entity': 'timing', 'similarities': 0.18207678}]}]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.multiple_predict(\n",
    "    [\n",
    "        \"Hola como te encuentras?\",\n",
    "        \"Hola puedes ayudarme con un problema con python?\",\n",
    "        \"describeme usando un meme\",\n",
    "    ],\n",
    "    threshold=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peque_nlu.feature_extractors import NaiveFeatureExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = NaiveFeatureExtractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hectorpulido/own-projects/peque-nlu/.venv/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/hectorpulido/own-projects/peque-nlu/.venv/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['algun', 'com', 'contr', 'cuand', 'desd', 'dond', 'durant', 'eram', 'estab', 'estais', 'estam', 'estan', 'estand', 'estaran', 'estaras', 'esteis', 'estem', 'esten', 'estes', 'estuv', 'fuer', 'fues', 'fuim', 'fuist', 'hab', 'habr', 'habran', 'habras', 'hast', 'hem', 'hub', 'mas', 'mia', 'mias', 'mio', 'mios', 'much', 'nad', 'nosotr', 'nuestr', 'par', 'per', 'poc', 'porqu', 'qui', 'seais', 'seam', 'sent', 'ser', 'seran', 'seras', 'si', 'sient', 'sint', 'sobr', 'som', 'suy', 'tambien', 'tant', 'ten', 'tendr', 'tendran', 'tendras', 'teng', 'tien', 'tod', 'tuv', 'tuy', 'vosotr', 'vuestr'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = ModelIntentClassifier(\"spanish\", feature_extractor=extractor)\n",
    "model.fit(\"intents_example.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intends': [{'text': 'Quiero aprender sobre lo último de python',\n",
       "   'intent': 'search',\n",
       "   'probability': 0.6911953107639961,\n",
       "   'features': [{'word': 'ultimo', 'entity': 'timing', 'similarities': 1},\n",
       "    {'word': 'python', 'entity': 'technology', 'similarities': 1}]}]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(\n",
    "    \"Quiero aprender sobre lo último de python\",\n",
    "    threshold=0.1,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
